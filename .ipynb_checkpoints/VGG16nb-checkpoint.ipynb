{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7326d49-dfb8-4148-a3e5-b21b8eef3dd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sauga\\AppData\\Local\\Temp\\ipykernel_31236\\2010863792.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import math\n",
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a401565-a2d6-4a2f-a479-66e2500b9e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization, Activation\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.pooling import MaxPool2D\n",
    "from keras.layers import concatenate\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l1, l2\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras import regularizers\n",
    "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4577b2ff-4d59-4d39-a24d-635447bad78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3bd6a902-d8ee-43d7-8908-b95bd2c9a467",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_gen = ImageDataGenerator(rescale=1./255)\n",
    "validation_data_gen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "563423cc-0475-41ec-8dfe-6a3d1dfb568a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 66701 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_data_gen.flow_from_directory(\n",
    "    'Augmented Train/train',\n",
    "    target_size=(48, 48),\n",
    "    batch_size=64,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "27e56f66-a0af-428f-a7e8-842c1fa2f28a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5212 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = validation_data_gen.flow_from_directory(\n",
    "    'Augmented Train/test',\n",
    "    target_size=(48, 48),\n",
    "    batch_size=64,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf02e71-7e97-4579-b4b2-9b10334c0013",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_batches = []\n",
    "y_test_batches = []\n",
    "\n",
    "for i in range(len(validation_generator)):\n",
    "    X_test, y_test = validation_generator.next()\n",
    "    X_test_batches.append(X_test)\n",
    "    y_test_batches.append(y_test)\n",
    "\n",
    "X_test = np.concatenate(X_test_batches, axis=0)\n",
    "y_test = np.concatenate(y_test_batches, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15441cd5-b82d-4fa7-a01c-075aa52c3f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_batches = []\n",
    "y_train_batches = []\n",
    "\n",
    "for i in range(len(train_generator)):\n",
    "    X_train, y_train = train_generator.next()\n",
    "    X_train_batches.append(X_train)\n",
    "    y_train_batches.append(y_train)\n",
    "\n",
    "X_train = np.concatenate(X_train_batches, axis=0)\n",
    "y_train = np.concatenate(y_train_batches, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f838f64-d547-4c87-8780-76f0d63753eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the VGG16 model with pretrained weights\n",
    "vgg16 = VGG16(weights='imagenet', include_top=False, input_shape=(48, 48, 3))\n",
    "\n",
    "# Freeze the layers of the VGG16 model\n",
    "for layer in vgg16.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90d50e91-79e8-4edf-b0a0-f07ce969af88",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(vgg16)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dense(4, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1e57e360-cccd-4954-bdbe-072a7ac5e7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " vgg16 (Functional)          (None, 1, 1, 512)         14714688  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               262656    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 2052      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 14,979,396\n",
      "Trainable params: 264,708\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16a91b00-ae88-4d5d-bc49-fd9f15f5ca99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n",
      "TensorFlow will use the GPU\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "if tf.config.list_physical_devices('GPU'):\n",
    "    print(\"TensorFlow will use the GPU\")\n",
    "else:\n",
    "    print(\"TensorFlow cannot find the GPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "622f49f9-45b6-4211-bf94-5d08c0f7e20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.ocl.setUseOpenCL(False)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(\n",
    "    learning_rate=0.0001), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "db801e5d-3c49-49de-8387-9a4d720d32ba",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (2829371283.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[13], line 3\u001b[1;36m\u001b[0m\n\u001b[1;33m    steps_per_epoch=21005/64\u001b[0m\n\u001b[1;37m                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "emotion_model_info = model.fit(\n",
    "    x=train_generator,\n",
    "    steps_per_epoch=21005/64,\n",
    "    epochs=60,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=5212/64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f2e2fc-6ceb-483c-86bb-8cb930396560",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
